<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>EEE 451: AI Models for Smart Attendance</title>

		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/reset.min.css">
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/reveal.min.css">
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/theme/black.min.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/monokai.min.css">
        <style>
            .reveal h1, .reveal h2, .reveal h3 {
                color: #00bcd4;
                text-transform: none;
            }
            .reveal section img {
                border: 2px solid #00bcd4;
                border-radius: 10px;
                padding: 10px;
                background: white;
            }
            .highlight-box {
                background: rgba(0, 188, 212, 0.1);
                border-left: 5px solid #00bcd4;
                padding: 20px;
                margin-top: 20px;
                text-align: left;
            }
            .model-grid {
                display: grid;
                grid-template-columns: 1fr 1fr;
                gap: 20px;
            }
        </style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
                <!-- Slide 1: Title -->
				<section>
                    <h1>EEE 451 Project</h1>
                    <h3>AI Models for Smart Attendance System</h3>
                    <p style="margin-top: 50px; font-size: 0.8em; color: #888;">
                        Deep Dive into Face Detection, Recognition, and Anti-Spoofing
                    </p>
                </section>

                <!-- Slide 2: Overview -->
                <section>
                    <h2>System Pipeline Overview</h2>
                    <div class="highlight-box">
                        <ol>
                            <li><strong>Image Acquisition:</strong> Capturing live frames via OpenCV.</li>
                            <li><strong>Face Detection:</strong> Locating the face using <strong>YuNet</strong>.</li>
                            <li><strong>Liveness Check:</strong> Verifying the user is real (not a photo).</li>
                            <li><strong>Alignment & Cropping:</strong> Normalizing the face.</li>
                            <li><strong>Face Recognition:</strong> Feature extraction with <strong>SFace</strong>.</li>
                            <li><strong>Matching:</strong> Similarity scoring against stored student database.</li>
                        </ol>
                    </div>
                </section>

                <!-- Slide 3: YuNet -->
                <section>
                    <section>
                        <h2>Model 1: YuNet</h2>
                        <p>High-Performance Face Detection</p>
                        <div class="model-grid">
                            <div>
                                <ul style="font-size: 0.8em;">
                                    <li><strong>Type:</strong> Deep Learning-based detector.</li>
                                    <li><strong>Key Advantage:</strong> Extremely fast (designed for edge devices).</li>
                                    <li><strong>Capability:</strong> Detects faces + 5 landmarks (eyes, nose, mouth corners).</li>
                                    <li><strong>Resilience:</strong> Robust to head tilt, lighting, and occlusions.</li>
                                </ul>
                            </div>
                            <div style="font-size: 0.7em; background: #222; padding: 10px; border-radius: 10px;">
                                <code>detector = cv2.FaceDetectorYN.create(<br>
                                    &nbsp;&nbsp;model_path,<br>
                                    &nbsp;&nbsp;input_size=(W, H),<br>
                                    &nbsp;&nbsp;score_threshold=0.9<br>
                                )</code>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Technical Detail: Landmarks</h3>
                        <p>YuNet provides 15 points in total for each detection:</p>
                        <ul style="font-size: 0.8em;">
                            <li><strong>[0-3]:</strong> Bounding Box (x, y, w, h).</li>
                            <li><strong>[4]:</strong> Confidence Score.</li>
                            <li><strong>[5-14]:</strong> (x, y) coordinates for 5 landmarks.</li>
                        </ul>
                        <div class="highlight-box" style="font-size: 0.7em;">
                            Landmarks are critical for <strong>face alignment</strong> (rotation correction) and <strong>liveness detection</strong>.
                        </div>
                    </section>
                </section>

                <!-- Slide 4: SFace -->
                <section>
                    <section>
                        <h2>Model 2: SFace</h2>
                        <p>Face Recognition & Embedding Extraction</p>
                        <div class="model-grid">
                            <div>
                                <ul style="font-size: 0.8em;">
                                    <li><strong>What is it?</strong> A specialized CNN for extracting "Identity Embeddings".</li>
                                    <li><strong>The Embedding:</strong> A 128-dimensional floating point vector.</li>
                                    <li><strong>The Logic:</strong> Two images of the same person will have "close" vectors.</li>
                                    <li><strong>Model File:</strong> <code>face_recognition_sface_2021dec.onnx</code></li>
                                </ul>
                            </div>
                            <div style="font-size: 0.7em; background: #222; padding: 10px; border-radius: 10px;">
                                <code>recognizer = cv2.FaceRecognizerSF.create(<br>
                                    &nbsp;&nbsp;model_path, ""<br>
                                )<br>
                                aligned = recognizer.alignCrop(img, face)<br>
                                embedding = recognizer.feature(aligned)</code>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Matching Mechanism</h3>
                        <p>How we verify identity:</p>
                        <div class="highlight-box">
                            <ul style="font-size: 0.8em;">
                                <li><strong>Cosine Similarity:</strong> Measures the angle between vectors (1.0 = identical).</li>
                                <li><strong>Euclidean Distance:</strong> Measures the physical distance between points.</li>
                                <li><strong>Thresholding:</strong> We use a <strong>0.363</strong> threshold for SFace to distinguish between individuals accurately.</li>
                            </ul>
                        </div>
                    </section>
                </section>

                <!-- Slide 5: Liveness Detection -->
                <section>
                    <section>
                        <h2>AI Logic: Liveness Detection</h2>
                        <p>Preventing Attendance Fraud</p>
                        <div class="highlight-box" style="font-size: 0.8em;">
                            The system includes custom algorithms to detect if a 3D living face is present vs. a 2D screen/print.
                        </div>
                        <ul style="font-size: 0.7em;">
                            <li><strong>Blur Analysis (Laplacian):</strong> Detects low-quality screen re-captures.</li>
                            <li><strong>Geometry Check:</strong> Eye-distance vs Bounding Box ratio.</li>
                            <li><strong>Challenge-Response:</strong> Requests the student to "Turn Left" or "Turn Right".</li>
                        </ul>
                    </section>
                    <section>
                        <h3>Nose Ratio Challenge</h3>
                        <p style="font-size: 0.8em;">Using YuNet landmarks to track 3D orientation:</p>
                        <div style="font-size: 0.7em; background: #222; padding: 10px; border-radius: 10px; text-align: left;">
                            <code>nose_x = landmarks[2][0]</code><br>
                            <code>ratio = (nose_x - bbox_x) / bbox_width</code><br>
                            <br>
                            - <strong>Ratio < 0.4:</strong> Face turned Left.<br>
                            - <strong>Ratio > 0.6:</strong> Face turned Right.<br>
                            - <strong>Ratio ~ 0.5:</strong> Face centered.
                        </div>
                    </section>
                </section>

                <!-- Slide 6: Background Research -->
                <section>
                    <h2>Background Research</h2>
                    <p style="font-size: 0.8em;">Why these models? (Comparison)</p>
                    <table style="font-size: 0.5em; width: 100%;">
                        <thead>
                            <tr style="background: #00bcd4; color: black;">
                                <th>Model</th>
                                <th>Pros</th>
                                <th>Cons</th>
                                <th>Project Role</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>YuNet</strong></td>
                                <td>Super fast, ONNX native</td>
                                <td>Small model capacity</td>
                                <td><strong>Chosen (Detection)</strong></td>
                            </tr>
                            <tr>
                                <td><strong>RetinaFace</strong></td>
                                <td>Highly accurate</td>
                                <td>Heavy, GPU intensive</td>
                                <td>Research baseline</td>
                            </tr>
                            <tr>
                                <td><strong>SFace</strong></td>
                                <td>Optimal for embedded devices</td>
                                <td>Sensitive to alignment</td>
                                <td><strong>Chosen (Recognition)</strong></td>
                            </tr>
                            <tr>
                                <td><strong>ArcFace</strong></td>
                                <td>Industry gold standard</td>
                                <td>Large model size</td>
                                <td>Reference model</td>
                            </tr>
                        </tbody>
                    </table>
                </section>

                <!-- Slide 7: Conclusion -->
                <section>
                    <h2>Conclusion</h2>
                    <ul style="font-size: 0.8em;">
                        <li><strong>Efficiency:</strong> Combined YuNet + SFace pipeline allows real-time processing on standard laptops/Raspberry Pi.</li>
                        <li><strong>Security:</strong> Multi-layer liveness detection mitigates simple spoofing attacks.</li>
                        <li><strong>Accuracy:</strong> Landmark-based alignment ensures high-precision face matching.</li>
                    </ul>
                    <div style="margin-top: 50px; font-weight: bold; color: #00bcd4;">
                        Thank You!
                    </div>
                </section>
			</div>
		</div>

		<script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/reveal.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/plugin/notes/notes.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/plugin/markdown/markdown.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/plugin/highlight/highlight.min.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
